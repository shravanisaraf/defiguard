# DeFiGuard ğŸ›¡ï¸

**Final Year Engineering Project**
**Title:** Real-time Fraud Detection in DeFi (Ethereum) using Hybrid GNN + Federated Learning

-----

## ğŸ“– Project Summary

DeFiGuard ingests historical Ethereum transaction data (from Kaggle) for model training and uses Alchemy WebSocket for a live transaction stream. We build features, create graph snapshots, train a hybrid **Graph Neural Network (GNN) + Transformer** classifier, and demonstrate **federated learning** using Flower. A FastAPI model server + Streamlit dashboard provide real-time inference and visualization.

-----

## ğŸ“‚ Project Structure

```
defiguard/
â”œâ”€ data/                 # datasets (raw parquet, kaggle, labels)
â”œâ”€ realtime/             # realtime SQLite DB
â”œâ”€ src/                  # code modules (ingestion, features, models, federated, serve, demo)
â”œâ”€ notebooks/            # Jupyter exploration
â”œâ”€ docs/                 # documentation and setup logs
```

-----

## âš™ï¸ Setup Instructions

### 1\. Clone repo

```bash
git clone git@github.com:shravanisaraf/defiguard.git
cd defiguard
```

### 2\. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3\. Install dependencies

```bash
pip install -r requirements.txt
```

### 4\. Environment variables

Copy `.env.example` to `.env` and fill in your keys:

```
ETH_ALCHEMY_WS=wss://eth-mainnet.g.alchemy.com/v2/YOUR_KEY
ETHERSCAN_API_KEY=YOUR_KEY
KAGGLE_KTX_PATH=data/raw/kaggle/transactions.csv
SQLITE_DB_PATH=realtime/realtime.db
LABELS_CSV=data/raw/labels.csv
```

### 5\. Test connection

```bash
python test_alchemy_ws.py
```

Expected output:

```
Connected: True
Latest block: 179xxxx
```

-----

## ğŸ‘©â€ğŸ’» Contributors

  * **Shravani Saraf** â€” Data & Infra Lead
  * **Teammate B** â€” Models & ML Lead
  * **Teammate C** â€” Federated & Serving Lead

-----

## âœ… Day 1 Status

  * Repo structure initialized âœ…
  * Env + Alchemy WS tested âœ…
  * Kaggle dataset path prepared âœ…
  * Labels stub committed âœ…
  * Next: features & realtime ingestion (Day 2)
